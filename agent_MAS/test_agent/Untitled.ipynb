{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = false)\n",
      " |    |-- width: integer (nullable = false)\n",
      " |    |-- nChannels: integer (nullable = false)\n",
      " |    |-- mode: integer (nullable = false)\n",
      " |    |-- data: binary (nullable = false)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# necessary import \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.sql.functions import lit\n",
    "from functools import reduce\n",
    "# create a spark session\n",
    "spark = SparkSession.builder.appName('DigitRecog').getOrCreate()\n",
    "# loaded image\n",
    "zero = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/0\").withColumn(\"label\", lit(0))\n",
    "one = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/1\").withColumn(\"label\", lit(1))\n",
    "two = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/2\").withColumn(\"label\", lit(2))\n",
    "three = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/3\").withColumn(\"label\", lit(3))\n",
    "four = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/4\").withColumn(\"label\", lit(4))\n",
    "five = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/5\").withColumn(\"label\", lit(5))\n",
    "six = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/6\").withColumn(\"label\", lit(6))\n",
    "seven = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/7\").withColumn(\"label\", lit(7))\n",
    "eight = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/8\").withColumn(\"label\", lit(8))\n",
    "nine = ImageSchema.readImages(\"home/daniel/intership_supanut/numdata/9\").withColumn(\"label\", lit(9))\n",
    "dataframes = [zero, one, two, three,four,\n",
    "             five, six, seven, eight, nine]\n",
    "# merge data frame\n",
    "df = reduce(lambda first, second: first.union(second), dataframes)\n",
    "# repartition dataframe \n",
    "df = df.repartition(200)\n",
    "# split the data-frame\n",
    "train, test = df.randomSplit([0.8, 0.2], 42)\n",
    "df.printSchema()\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from sparkdl import DeepImageFeaturizer\n",
    "# model: InceptionV3\n",
    "# extracting feature from images\n",
    "featurizer = DeepImageFeaturizer(inputCol=\"image\",\n",
    "                                 outputCol=\"features\",\n",
    "                                 modelName=\"InceptionV3\")\n",
    "# used as a multi class classifier\n",
    "lr = LogisticRegression(maxIter=5, regParam=0.03, \n",
    "                        elasticNetParam=0.5, labelCol=\"label\")\n",
    "# define a pipeline model\n",
    "sparkdn = Pipeline(stages=[featurizer, lr])\n",
    "spark_model = sparkdn.fit(train) # start fitting or training\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# evaluate the model with test set\n",
    "evaluator = MulticlassClassificationEvaluator() \n",
    "tx_test = spark_model.transform(test)\n",
    "print('F1-Score ', evaluator.evaluate(tx_test, \n",
    "                                      {evaluator.metricName: 'f1'}))\n",
    "print('Precision ', evaluator.evaluate(tx_test,\n",
    "                                       {evaluator.metricName:                    'weightedPrecision'}))\n",
    "print('Recall ', evaluator.evaluate(tx_test, \n",
    "                                    {evaluator.metricName: 'weightedRecall'}))\n",
    "print('Accuracy ', evaluator.evaluate(tx_test, \n",
    "                                      {evaluator.metricName: 'accuracy'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
